{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a031080d-7e3b-4add-9109-ec625d54a75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import json\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import DataLoader, Dataset, SubsetRandomSampler\n",
    "import more_itertools as mit\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from spot import SPOT\n",
    "from mtad_gat import MTAD_GAT\n",
    "from trainer import Trainer\n",
    "from predictor import Predictor\n",
    "from utils import *\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "#da cambiare tensorboard con WandB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c331eca3-4103-40dd-bef0-1191e7a7a1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# da definire tutti manualmente, poi vedere valori di default in args\n",
    "\n",
    "#dataset = args.dataset\n",
    "window_size = 100\n",
    "spec_res = False\n",
    "normalize = False\n",
    "n_epochs = 50\n",
    "batch_size = 512\n",
    "init_lr = 1e-3\n",
    "val_split = 0.1\n",
    "shuffle_dataset = False\n",
    "use_cuda = True\n",
    "print_every = 1\n",
    "log_tensorboard = True\n",
    "#group_index = args.group[0]True\n",
    "#index = args.group[2:]\n",
    "#args_summary = str(args.__dict__)\n",
    "#print(args_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0e3244b-a8ec-4276-88cc-3073404f110d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mget_data\u001b[49m()\n\u001b[1;32m      3\u001b[0m timestamp \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;66;03m#salvo il timestamp per dopo\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#df.set_index(\"timestamp\", inplace=True)\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_data' is not defined"
     ]
    }
   ],
   "source": [
    "df = get_data()\n",
    "\n",
    "timestamp = df[\"timestamp\"] #salvo il timestamp per dopo\n",
    "#df.set_index(\"timestamp\", inplace=True)\n",
    "\n",
    "to_drop = [\n",
    "    \"sin\",\n",
    "    \"cos\",\n",
    "    \"2m\",\n",
    "    \"soil\",\n",
    "    \"rain\",\n",
    "    \"timestamp\"\n",
    "]\n",
    "\n",
    "for col in df:\n",
    "    if all(key in col for key in to_drop):\n",
    "        df.drop(columns=col, inplace=True)\n",
    "    \n",
    "\n",
    "#df.drop(columns=\"timestamp, \", inplace=True)\n",
    "train_data = df.to_numpy()\n",
    "x_dim = len(df.columns)# numero di colonne\n",
    "train_data = train_data.reshape((-1, x_dim))#[train_start:train_end, :]\n",
    "    \n",
    "x_train, x_test = train_test_split(train_data, train_size=0.8)\n",
    "\n",
    "# converte il dataframe in un tensore\n",
    "x_train = torch.from_numpy(x_train).float()\n",
    "\n",
    "x_test = torch.from_numpy(x_test).float()\n",
    "# Il secondo argomento del tensore sono il numero di colonne del dataframe\n",
    "n_features = x_train.shape[1]\n",
    "out_dim = n_features\n",
    "target_dims = None # if none models all features\n",
    "# si crea la cartella di output\n",
    "log_dir = './logs'\n",
    "save_path = \"./fv_model\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ede6183-a353-4442-adab-fed983eef521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inizializza il modello\n",
    "model = MTAD_GAT(\n",
    "    n_features,\n",
    "    window_size,\n",
    "    out_dim,\n",
    "    kernel_size=7,\n",
    "    use_gatv2=True,\n",
    "    feat_gat_embed_dim=None,\n",
    "    time_gat_embed_dim=None,\n",
    "    gru_n_layers=1,\n",
    "    gru_hid_dim=150,\n",
    "    forecast_n_layers=3,\n",
    "    forecast_hid_dim=150,\n",
    "    recon_n_layers=1,\n",
    "    recon_hid_dim=150,\n",
    "    dropout=0.3,\n",
    "    alpha=0.2\n",
    ")\n",
    "\n",
    "# inizializza optimizer e robe varie\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=init_lr)\n",
    "forecast_criterion = nn.MSELoss()\n",
    "recon_criterion = nn.MSELoss()\n",
    "\n",
    "# altre robe di pytorch\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    optimizer,\n",
    "    window_size,\n",
    "    n_features,\n",
    "    target_dims,\n",
    "    n_epochs,\n",
    "    batch_size,\n",
    "    init_lr,\n",
    "    forecast_criterion,\n",
    "    recon_criterion,\n",
    "    use_cuda,\n",
    "    save_path,\n",
    "    log_dir,\n",
    "    print_every,\n",
    "    log_tensorboard=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7471251f-f89d-4e7e-8bf9-c95677a91129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting and calculating anomaly scores..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58/58 [00:00<00:00, 59.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting and calculating anomaly scores..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 115.82it/s]\n",
      "/home/jovyan/anomaly-detection-no-gpu-volume-30/deep/spot.py:305: RuntimeWarning: divide by zero encountered in log\n",
      "  return 1 + np.log(s).mean()\n",
      "/home/jovyan/anomaly-detection-no-gpu-volume-30/deep/spot.py:308: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  return np.mean(1 / s)\n",
      "/home/jovyan/anomaly-detection-no-gpu-volume-30/deep/spot.py:321: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  jac_vs = (1 / t) * (-vs + np.mean(1 / s ** 2))\n",
      "/home/jovyan/anomaly-detection-no-gpu-volume-30/deep/spot.py:321: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  jac_vs = (1 / t) * (-vs + np.mean(1 / s ** 2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running POT with q=0.005, level=0.95..\n",
      "Initial threshold : 0.4997896\n",
      "Number of peaks : 729\n",
      "Grimshaw maximum log-likelihood estimation ... [done]\n",
      "\tγ = -0.32017773389816284\n",
      "\tσ = 0.05192852913196731\n",
      "\tL = 1660.7091658930503\n",
      "Extreme quantile (probability = 0.005): 0.5843481942861153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3641/3641 [00:00<00:00, 4375776.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "3641\n",
      "Results using epsilon method:\n",
      " {'threshold': 0.6116647720336914, 'reg_level': 1}\n",
      "Results using peak-over-threshold method:\n",
      " {'threshold': 0.5843481942861154}\n",
      "Results using best f1 score search:\n",
      " {}\n",
      "Saving output to ./results//<train/test>_output.pkl\n",
      "-- Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.load(f\"{save_path}/model.pt\")\n",
    "prediction_args = {\n",
    "    \"target_dims\": target_dims,\n",
    "    'scale_scores': False,\n",
    "    \"level\": 0.95,\n",
    "    \"q\": 0.005,\n",
    "    'dynamic_pot': False,\n",
    "    \"use_mov_av\": False,\n",
    "    \"gamma\": 1,\n",
    "    \"reg_level\": 1,\n",
    "    \"save_path\": \"./results/\",\n",
    "}\n",
    "best_model = trainer.model\n",
    "predictor = Predictor(\n",
    "    best_model,\n",
    "    window_size,\n",
    "    n_features,\n",
    "    prediction_args,\n",
    ")\n",
    "y_test=None\n",
    "label = y_test[window_size:] if y_test is not None else None\n",
    "predictor.predict_anomalies(x_train, x_test, label)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
